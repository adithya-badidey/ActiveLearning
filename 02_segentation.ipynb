{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Python Path\n",
      "Project Root Path: /home/default/workspace\n",
      "Project Source Root Path: /home/default/workspace/ActiveLearning\n",
      "Project Data Path: /home/default/workspace/ActiveLearning/data\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "# To be able to reference packages/modules in this repository, this\n",
    "# relative path must be added to the python path. Your notebook may be \n",
    "# in a different folder, so modify this variable to point to the src \n",
    "# folder.\n",
    "proj_notebooks_root = pathlib.Path().absolute()\n",
    "proj_root_path = proj_notebooks_root.parent\n",
    "data_path = proj_notebooks_root / \"data\"\n",
    "\n",
    "if proj_root_path not in sys.path:\n",
    "    sys.path.insert(0, proj_root_path.as_posix())\n",
    "    print(\"Updated Python Path\")\n",
    "\n",
    "print(f\"Project Root Path: {proj_root_path}\")\n",
    "print(f\"Project Source Root Path: {proj_notebooks_root}\")\n",
    "print(f\"Project Data Path: {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch: \t\t 1.13.0+cu116\n",
      "GPU:         \t\t NVIDIA A100 80GB PCIe MIG 2g.20gb\n",
      "Memory Usage:\t 0.0 GB /  0.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.13) or chardet (5.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "# from torchinfo import summary\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "debug = False\n",
    "\n",
    "print(\"Pytorch: \\t\\t\", torch.__version__)\n",
    "if not debug and torch.cuda.is_available():\n",
    "    device='cuda'\n",
    "    print('GPU:         \\t\\t', torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:\\t',\n",
    "        round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB / ',\n",
    "        round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    print(\"GPU is **not available**\")\n",
    "    device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kaggle\n",
    "# ! cp {proj_notebooks_root / 'kaggle.json'} ~/.kaggle/kaggle.json\n",
    "# ! chmod 600 ~/.kaggle/kaggle.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-15 20:58:57--  https://data.lib.vt.edu/ndownloader/articles/16625056/versions/1\n",
      "Resolving data.lib.vt.edu (data.lib.vt.edu)... 52.214.33.39, 63.32.251.213, 2a05:d018:1f4:d003:9b76:e1dc:c675:2471, ...\n",
      "Connecting to data.lib.vt.edu (data.lib.vt.edu)|52.214.33.39|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1028474638 (981M) [application/zip]\n",
      "Saving to: ‘/home/default/workspace/ActiveLearning/data/1’\n",
      "\n",
      "1                   100%[===================>] 980.83M  19.1MB/s    in 53s     \n",
      "\n",
      "2022-12-15 20:59:51 (18.5 MB/s) - ‘/home/default/workspace/ActiveLearning/data/1’ saved [1028474638/1028474638]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# base_dir = data_path / 'crack_segmentation_dataset'\n",
    "# if not base_dir.exists():\n",
    "#     ! kaggle datasets download -p {data_path.as_posix()} -d lakshaymiddha/crack-segmentation-dataset\n",
    "#     ! unzip -q {data_path / 'crack-segmentation-dataset.zip'} -d {data_path}\n",
    "#     ! rm {data_path / 'crack-segmentation-dataset.zip'} \n",
    "# else:\n",
    "#     print(\"Found dataset at \", base_dir.as_posix())\n",
    "\n",
    "base_dir = data_path / 'ConglomerateConcreteCrackDataset'\n",
    "if not base_dir.exists():\n",
    "    dataset_url = 'https://data.lib.vt.edu/ndownloader/articles/16625056/versions/1'\n",
    "\n",
    "    ! wget {dataset_url} -P {data_path}\n",
    "    ! unzip -q {data_path / '1'} -d {data_path}\n",
    "    ! unzip -q {data_path / 'Conglomerate\\ Concrete\\ Crack\\ Detection.zip'} -d {data_path}\n",
    "    ! mv {data_path/'Conglomerate\\ Concrete\\ Crack\\ Detection'} {base_dir}\n",
    "    ! mv {data_path / 'README_congl_dataset.rtf'}  {data_path/'ConglomerateConcreteCrackDataset'}     \n",
    "    ! rm {data_path / 'Conglomerate\\ Concrete\\ Crack\\ Detection.zip'}\n",
    "    ! rm {data_path / '1'}\n",
    "else:\n",
    "    print(\"Found dataset at \", base_dir.as_posix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(data):\n",
    "    return data.replace('<br />', '')\n",
    "\n",
    "class ArrayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, array, image_transforms=None, both_transforms=None):\n",
    "        self.array = array\n",
    "                \n",
    "        self.image_transforms = image_transforms\n",
    "        self.both_transforms = both_transforms\n",
    "        self.segment_transforms = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.array)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        id, imagePath, segmentPath = self.array[index]\n",
    "        image = Image.open(imagePath).convert('RGB')\n",
    "        segment = Image.open(segmentPath).convert('L')\n",
    "        segment = self.segment_transforms(segment)        \n",
    "            \n",
    "        if self.image_transforms is not None:\n",
    "            image = self.image_transforms(image)\n",
    "            \n",
    "        if self.both_transforms is not None:\n",
    "            image = self.both_transforms(image)\n",
    "            segment = self.both_transforms(segment)\n",
    "        \n",
    "        # print(image.shape, segment.shape)\n",
    "\n",
    "        if image.shape != (3, 448, 448):\n",
    "            print(f\"Image shape is {image.shape}\")\n",
    "        if segment.shape != (1, 448, 448):\n",
    "            print(f\"Segment shape is {segment.shape}\")\n",
    "        \n",
    "        return image, segment\n",
    "\n",
    "    def indices(self):\n",
    "        return self.array[:,0]\n",
    "\n",
    "    def split(self, p=0.5):\n",
    "        count = len(self.array)\n",
    "        index = np.arange(count)\n",
    "        first = int(count * p)\n",
    "        return [\n",
    "            ArrayDataset(self.array[index[:first]], \n",
    "                    image_transforms=self.image_transforms,\n",
    "                    both_transforms=self.both_transforms), \n",
    "            ArrayDataset(self.array[index[first:]], \n",
    "                    image_transforms=self.image_transforms,\n",
    "                    both_transforms=self.both_transforms)\n",
    "        ]\n",
    "\n",
    "    def pop(self, indices):\n",
    "        fltr = np.isin(self.array[:, 0], indices)\n",
    "        # print(fltr)\n",
    "        removed = ArrayDataset(self.array[fltr], \n",
    "                    image_transforms=self.image_transforms,\n",
    "                    both_transforms=self.both_transforms)\n",
    "        self.array = self.array[~fltr]\n",
    "        return removed\n",
    "\n",
    "    def addLabels(self, labels):\n",
    "        self.array = np.hstack([self.array, np.expand_dims(labels, axis=1)])\n",
    "        return self\n",
    "\n",
    "    def addData(self, otherArrayDataset):\n",
    "        self.array = np.append(self.array, otherArrayDataset.array, axis=0)\n",
    "\n",
    "\n",
    "class UnlabelledDataset(ArrayDataset):    \n",
    "    def __getitem__(self, index):\n",
    "        id, imagePath = self.array[index]\n",
    "        image = Image.open(imagePath)\n",
    "            \n",
    "        if self.image_transforms is not None:\n",
    "            image = self.image_transforms(image)\n",
    "            \n",
    "        if self.both_transforms is not None:\n",
    "            image = self.both_transforms(image)\n",
    "        \n",
    "        return image, id\n",
    "\n",
    "\n",
    "class OracleDataset():\n",
    "    def __init__(self, array):\n",
    "        self.array = array\n",
    "    def query(self, indices):\n",
    "        return self.array[np.isin(self.array[:, 0], indices),1]\n",
    "\n",
    "\n",
    "def init():\n",
    "    X_dir = base_dir/'train'/'images'\n",
    "    y_dir = base_dir/'train'/'masks'\n",
    "\n",
    "    files = [y for y in X_dir.glob('*')] \n",
    "\n",
    "    for i in files:\n",
    "        assert((y_dir / i.name).exists())\n",
    "\n",
    "    data = np.array([(id, i, (y_dir / i.name)) for id, i in enumerate(files)])\n",
    "    # print(all_data)\n",
    "    oracle_data = data[:,[0, 2]]\n",
    "    unlabelled_data = data[:,[0, 1]]\n",
    "    data_transforms = {\n",
    "        'both': transforms.Compose([\n",
    "    #         transforms.CenterCrop((630, 1024))\n",
    "        ]),\n",
    "        'images': transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    oracle_dataset = OracleDataset(oracle_data)\n",
    "    unlabelled_dataset = UnlabelledDataset(unlabelled_data,\n",
    "                              image_transforms=data_transforms['images'], \n",
    "                              both_transforms=data_transforms['both'])\n",
    "    return unlabelled_dataset, oracle_dataset\n",
    "\n",
    "def random_query(dataset, count, model=None, device=None):\n",
    "    return np.random.choice(dataset.indices(), count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegModel(torch.nn.Module):\n",
    "    def __init__(self, numclasses):\n",
    "        super(SegModel, self).__init__()\n",
    "\n",
    "        self.fcn = torchvision.models.segmentation.fcn_resnet50(\n",
    "            weights=None, \n",
    "            num_classes = numclasses, \n",
    "            aux_loss = False,\n",
    "            weights_backbone=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "#         self.softmax = torch.nn.Softmax(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fcn(x)['out']\n",
    "#         x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "def get_eval_metrics(pred, gold, threshold = 0.5):\n",
    "    pred = (pred > threshold).long()\n",
    "    gold = gold.long()\n",
    "    hits = torch.sum(torch.mul(pred, gold)).item() #element-wise multiplication\n",
    "    shots = torch.sum(pred).item()\n",
    "    targets = torch.sum(gold).item()\n",
    "#     print(hits, shots, targets)\n",
    "    return hits, shots, targets\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, scaler, history=None, lr_sched=None):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    bar_format = \"{l_bar}{bar} {elapsed}<{remaining} {rate_fmt}{postfix}\"\n",
    "    \n",
    "    with tqdm(dataloader, unit=\"batch\", bar_format=bar_format) as tepoch:\n",
    "        for X, y in tepoch:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Runs the forward pass with autocasting.\n",
    "            with autocast():\n",
    "                output = model(X)\n",
    "                loss = loss_fn(output, y)\n",
    "\n",
    "                hits, shots, targets = get_eval_metrics(output, y)\n",
    "                total_hits += hits\n",
    "                total_shots += shots\n",
    "                total_targets += targets\n",
    "\n",
    "            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
    "            # Backward passes under autocast are not recommended.\n",
    "            # Backward ops run in the same dtype autocast chose for corresponding forward ops.\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "            # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "            # otherwise, optimizer.step() is skipped.\n",
    "            scaler.step(optimizer)\n",
    "\n",
    "            # Updates the scale for next iteration.\n",
    "            scaler.update()\n",
    "            \n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            if(lr_sched is not None):\n",
    "                lr_sched.step()\n",
    "\n",
    "            loss = loss.item()\n",
    "            tepoch.set_postfix(\n",
    "                loss=round(loss, 4), \n",
    "                lr=round(lr_sched.get_last_lr()[0], 4)\n",
    "            )\n",
    "\n",
    "    history['train_loss'].append(loss_sum/len(dataloader))\n",
    "    history['train_hits'].append(total_hits)\n",
    "    history['train_shots'].append(total_shots)\n",
    "    history['train_targets'].append(total_targets)\n",
    "    \n",
    "    if total_shots == 0:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        f1score = 0\n",
    "    else:\n",
    "        precision = total_hits/total_shots\n",
    "        recall = total_hits/total_targets\n",
    "        f1score = (2 * precision * recall)/(precision + recall)\n",
    "        \n",
    "\n",
    "    history['train_precision'].append(precision)\n",
    "    history['train_recall'].append(recall)\n",
    "    history['train_f1score'].append(f1score)\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, history):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    loss = 0\n",
    "    total_hits = 0\n",
    "    total_shots = 0\n",
    "    total_targets = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "#             print(y.shape)\n",
    "            \n",
    "            output = model(X)\n",
    "            \n",
    "            loss += loss_fn(output, y).item()\n",
    "            hits, shots, targets = get_eval_metrics(output, y)\n",
    "            total_hits += hits\n",
    "            total_shots += shots\n",
    "            total_targets += targets\n",
    "\n",
    "    loss /= num_batches\n",
    "    history['test_loss'].append(loss)\n",
    "    history['test_hits'].append(total_hits)\n",
    "    history['test_shots'].append(total_shots)\n",
    "    history['test_targets'].append(total_targets)\n",
    "    \n",
    "    if total_shots == 0:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        f1score = 0\n",
    "    else:\n",
    "        precision = total_hits/total_shots\n",
    "        recall = total_hits/total_targets\n",
    "        f1score = (2 * precision * recall)/(precision + recall)\n",
    "        \n",
    "\n",
    "    history['test_precision'].append(precision)\n",
    "    history['test_recall'].append(recall)\n",
    "    history['test_f1score'].append(f1score)\n",
    "\n",
    "\n",
    "def train_model(train_dataset, test_dataset,epochs=40):\n",
    "    history = {\n",
    "        'train_loss':[],\n",
    "        'train_hits':[],\n",
    "        'train_shots':[],\n",
    "        'train_targets':[],\n",
    "        'train_precision': [],\n",
    "        'train_recall': [],\n",
    "        'train_f1score': [],\n",
    "        'test_loss':[],\n",
    "        'test_hits':[],\n",
    "        'test_shots':[],\n",
    "        'test_targets':[],\n",
    "        'test_precision': [],\n",
    "        'test_recall': [],\n",
    "        'test_f1score': []\n",
    "    }\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            prefetch_factor=2,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=8)\n",
    "\n",
    "    test_dataloader = DataLoader(test_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=8)\n",
    "\n",
    "    model = SegModel(1)\n",
    "    model.to(device)\n",
    "        \n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.00001, momentum=0.9)\n",
    "\n",
    "    lr_sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                       max_lr=0.01, \n",
    "                       steps_per_epoch=len(train_dataloader), \n",
    "                       epochs=epochs)\n",
    "\n",
    "    for t in tqdm(range(epochs), bar_format=\"{elapsed} Elapsed | {percentage:3.0f}% done |{bar}| {n_fmt}/{total_fmt} [{remaining} remaining | {rate_fmt}{postfix}]\", unit=\"epoch\", total=epochs):\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer, history, lr_sched)\n",
    "        test_loop(test_dataloader, model, loss_fn, history)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# unlabelled_dataset, oracle = init()\n",
    "# print(f\"Starting with unlabelled dataset of size {len(unlabelled_dataset)}\")\n",
    "\n",
    "# chosen_indices = random_query(unlabelled_dataset, p)\n",
    "\n",
    "# train_dataset, test_dataset =  unlabelled_dataset.pop(chosen_indices)\\\n",
    "#                                     .addLabels(oracle.query(chosen_indices))\\\n",
    "#                                     .split(p=0.5)\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset,\n",
    "#                         batch_size=batch_size,\n",
    "#                         shuffle=True,\n",
    "#                         num_workers=1)\n",
    "\n",
    "# for _ in train_dataloader:\n",
    "#     pass\n",
    "# batch = next(iter(train_dataloader))\n",
    "# tensors = batch[0]\n",
    "# segments = batch[1]\n",
    "\n",
    "# # tensors, metadata\n",
    "# y = int(len(tensors)/2+0.5); x = 2\n",
    "# fig = plt.figure(figsize=(8*x, 5*y))\n",
    "\n",
    "# for i in range(min(len(tensors)//2, 3)):\n",
    "# #     print(y*100 + x*10 + i)\n",
    "#     ax = fig.add_subplot(y , x , (i*2) + 1)\n",
    "#     image = tensors[i].permute(1,2,0).cpu().numpy()\n",
    "#     image = (image - [image[:,:,0].min(), image[:,:,1].min(), image[:,:,2].min()])\n",
    "#     image = image/([image[:,:,0].max(), image[:,:,1].max(), image[:,:,2].max()])\n",
    "#     ax.set_axis_off()\n",
    "#     ax.imshow(image)\n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     ax = fig.add_subplot(y , x , (i*2) + 2)\n",
    "#     image = segments[i].permute(1,2,0).cpu().numpy()\n",
    "#     image = np.squeeze(image)\n",
    "# #     image = np.atleast_3d(image)\n",
    "#     ax.set_axis_off()\n",
    "#     ax.imshow(image)\n",
    "#     plt.tight_layout()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60, 60, 60]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initializing parameters\n",
    "batch_size = 16     # Reduce this if you get memory errors\n",
    "epochs = 30\n",
    "\n",
    "K = 300 # Total budget for labelling\n",
    "p = int(K * .4) # Number of examples to begin with\n",
    "n = 3\n",
    "ks = [(K-p)//n]*n\n",
    "ks[0] += K - p - sum(ks) # removes rounding errors\n",
    "\n",
    "ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "\n",
    "unlabelled_dataset, oracle = init()\n",
    "print(f\"Starting with unlabelled dataset of size {len(unlabelled_dataset)}\")\n",
    "\n",
    "chosen_indices = random_query(unlabelled_dataset, p)\n",
    "\n",
    "train_dataset, test_dataset =  unlabelled_dataset.pop(chosen_indices)\\\n",
    "                                    .addLabels(oracle.query(chosen_indices))\\\n",
    "                                    .split(p=0.5)\n",
    "print(f\"Randomly sampled train_dataset of size {len(train_dataset)} and test_dataset of size {len(test_dataset)}\")\n",
    "\n",
    "print(f\"Training new model ...\")\n",
    "model, stats = train_model(train_dataset, test_dataset, epochs=epochs)\n",
    "history.append(stats)\n",
    "\n",
    "for k in ks:\n",
    "    print(f\"Quering {k} items from the from  ...\")\n",
    "    chosen_indices = random_query(unlabelled_dataset, k)\n",
    "\n",
    "    newData = unlabelled_dataset.pop(chosen_indices)\\\n",
    "                          .addLabels(oracle.query(chosen_indices))\n",
    "    train_dataset.addData(newData)\n",
    "    print(f\"New train_dataset size: {len(train_dataset)}.\")\n",
    "    print(f\"Training new model ...\")\n",
    "    \n",
    "    model, stats = train_model(train_dataset, test_dataset, epochs=epochs)\n",
    "    history.append(stats)\n",
    "    \n",
    "\n",
    "\n",
    "#~ 1 minute per training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "for id, i in enumerate(history):\n",
    "    plt.plot(i['train_loss'], label=f'Loss {id+1}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Loss')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "for id, i in enumerate(history):\n",
    "    plt.plot(i['train_accuracy'], label=f'Accuracy {id+1}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "for id, i in enumerate(history):\n",
    "    plt.plot(i['test_loss'], label=f'Loss {id+1}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Test Loss')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "for id, i in enumerate(history):\n",
    "    plt.plot(i['test_accuracy'], label=f'Accuracy {id+1}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Test Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_least_confidence_query(dataset, query_size, model, device, deterministic=True):\n",
    "    confidences = []\n",
    "    indices = []\n",
    "\n",
    "    ul_dataloader = DataLoader(\n",
    "        dataset, \n",
    "        num_workers=8,\n",
    "        batch_size=batch_size, \n",
    "        collate_fn=partial(collate_unlabelled_batch, text_pipeline))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, idx in tqdm(ul_dataloader):\n",
    "            X = X.to(device)\n",
    "            probabilities = model['model'](X)\n",
    "            confidence = (torch.abs(probabilities - 0.5)*2).squeeze(dim=-1)\n",
    "            \n",
    "            confidences.extend(confidence.cpu().tolist())\n",
    "            indices.extend(idx)\n",
    "            \n",
    "    conf = np.asarray(confidences)\n",
    "    ind = np.asarray(indices)\n",
    "    sorted_pool = np.argsort(conf)\n",
    "    # Return the indices corresponding to the lowest `query_size` confidences\n",
    "    return ind[sorted_pool][0:query_size]\n",
    "\n",
    "\n",
    "history = []\n",
    "\n",
    "unlabelled_dataset, oracle = init()\n",
    "print(f\"Starting with unlabelled_dataset of size {len(unlabelled_dataset)}\")\n",
    "\n",
    "chosen_indices = random_query(unlabelled_dataset, p)\n",
    "\n",
    "train_dataset, test_dataset =  unlabelled_dataset.pop(chosen_indices)\\\n",
    "                                    .addLabels(oracle.query(chosen_indices))\\\n",
    "                                    .split(p=0.5)\n",
    "print(f\"Starting with randomly sampled train_dataset of size {len(train_dataset)} and test_dataset of size {len(test_dataset)}\")\n",
    "\n",
    "print(f\"Training new model ...\")\n",
    "model, stats = train_model(train_dataset, test_dataset, epochs=epochs)\n",
    "history.append(stats)\n",
    "\n",
    "for k in ks:\n",
    "    print(f\"Quering {k} items from the from  ...\")\n",
    "    chosen_indices = binary_least_confidence_query(unlabelled_dataset, k, model=model, device=device)\n",
    "\n",
    "    newData = unlabelled_dataset.pop(chosen_indices)\\\n",
    "                          .addLabels(oracle.query(chosen_indices))\n",
    "    train_dataset.addData(newData)\n",
    "    print(f\"New train_dataset size: {len(train_dataset)}.\")\n",
    "    print(f\"Training new model ...\")\n",
    "    \n",
    "    model, stats = train_model(train_dataset, test_dataset, epochs=epochs)\n",
    "    history.append(stats)\n",
    "    \n",
    "\n",
    "\n",
    "#~ 1 minute per training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "for id, i in enumerate(history):\n",
    "    plt.plot(i['train_loss'], label=f'Loss {id+1}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Loss')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "for id, i in enumerate(history):\n",
    "    plt.plot(i['train_accuracy'], label=f'Accuracy {id+1}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "for id, i in enumerate(history):\n",
    "    plt.plot(i['test_loss'], label=f'Loss {id+1}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Test Loss')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "for id, i in enumerate(history):\n",
    "    plt.plot(i['test_accuracy'], label=f'Accuracy {id+1}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Test Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(t):\n",
    "    return torch.var(t, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klDivergence(t):\n",
    "    return torch.sum((t * torch.log(t/torch.mean(t, axis=1).unsqueeze(-1))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(t):\n",
    "    return torch.sum(t * torch.log(t), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install baal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baal.bayesian.dropout import MCDropoutModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_disagreement_bald(unlabelled_dataset, k, model, disagreement=entropy, device=device, iterations=20):\n",
    "    entropies = []\n",
    "    indices = []\n",
    "\n",
    "    vocab = model['vocab']\n",
    "    model = model['model']\n",
    "    text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "    label_pipeline = lambda x: 1 if x == 'pos' else 0\n",
    "    \n",
    "    ul_dataloader = DataLoader(\n",
    "        unlabelled_dataset, \n",
    "        num_workers=8,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size, \n",
    "        collate_fn=partial(collate_unlabelled_batch, text_pipeline))\n",
    "\n",
    "    with MCDropoutModule(model) as mcdropout_model:\n",
    "        with torch.no_grad():\n",
    "            for X, ind in ul_dataloader:\n",
    "                X = X.to(device)\n",
    "                conf = torch.stack([mcdropout_model(X).squeeze() for _ in range(iterations)])\n",
    "                entropies.extend(entropy(conf.T).cpu())\n",
    "                indices.extend(ind)\n",
    "\n",
    "    entropies = torch.stack(entropies)\n",
    "    indices = torch.tensor(indices)\n",
    "    sorted_pool = torch.argsort(entropies, descending=True)\n",
    "    return indices[sorted_pool[k:]]\n",
    "\n",
    "\n",
    "history = []\n",
    "\n",
    "unlabelled_dataset, oracle = init()\n",
    "print(f\"Starting with unlabelled_dataset of size {len(unlabelled_dataset)}\")\n",
    "\n",
    "chosen_indices = random_query(unlabelled_dataset, p)\n",
    "\n",
    "train_dataset, test_dataset =  unlabelled_dataset.pop(chosen_indices)\\\n",
    "                                    .addLabels(oracle.query(chosen_indices))\\\n",
    "                                    .split(p=0.5)\n",
    "print(f\"Starting with randomly sampled train_dataset of size {len(train_dataset)} and test_dataset of size {len(test_dataset)}\")\n",
    "\n",
    "print(f\"Training new model ...\")\n",
    "model, stats = train_model(train_dataset, test_dataset, epochs=epochs)\n",
    "history.append(stats)\n",
    "\n",
    "for k in ks:\n",
    "    print(f\"Quering {k} items from the from  ...\")\n",
    "    chosen_indices = binary_disagreement_bald(unlabelled_dataset, k, model)\n",
    "\n",
    "    newData = unlabelled_dataset.pop(chosen_indices)\\\n",
    "                          .addLabels(oracle.query(chosen_indices))\n",
    "    train_dataset.addData(newData)\n",
    "    print(f\"New train_dataset size: {len(train_dataset)}.\")\n",
    "    print(f\"Training new model ...\")\n",
    "    \n",
    "    model, stats = train_model(train_dataset, test_dataset, epochs=epochs)\n",
    "    history.append(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "for id, i in enumerate(history):\n",
    "    plt.plot(i['train_loss'], label=f'Loss {id+1}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Loss')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "for id, i in enumerate(history):\n",
    "    plt.plot(i['train_accuracy'], label=f'Accuracy {id+1}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "for id, i in enumerate(history):\n",
    "    plt.plot(i['test_loss'], label=f'Loss {id+1}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Test Loss')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "for id, i in enumerate(history):\n",
    "    plt.plot(i['test_accuracy'], label=f'Accuracy {id+1}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Test Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "094e8a46ce80198b332a0d589ece882cd007e3d7e6ab8ab343ba7511982fe530"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
