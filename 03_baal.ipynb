{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KM6I2WSiBmMu"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import segmentation_models_pytorch as smp\n",
        "from segmentation_models_pytorch.base.modules import Activation\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "from baal import ActiveLearningDataset\n",
        "\n",
        "import argparse\n",
        "from copy import deepcopy\n",
        "from pprint import pprint\n",
        "\n",
        "import torch.backends\n",
        "from PIL import Image\n",
        "from torch import optim\n",
        "from torchvision.transforms import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "import baal\n",
        "# from baal import get_heuristic, ActiveLearningLoop\n",
        "# from baal.bayesian.dropout import MCDropoutModule\n",
        "# from baal import ModelWrapper\n",
        "# from baal import ClassificationReport\n",
        "# from baal import PILToLongTensor\n",
        "\n",
        "try:\n",
        "    import segmentation_models_pytorch as smp\n",
        "except ImportError:\n",
        "    raise Exception(\"This example requires `smp`.\\n pip install segmentation_models_pytorch\")\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OMYkCTgRWBxe"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpeLlZdACGwl",
        "outputId": "ef3a35dd-990b-40e2-de6c-f6ba9e22ae51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: baal in /usr/local/lib/python3.8/dist-packages (1.7.0)\n",
            "Requirement already satisfied: structlog<22.0.0,>=21.1.0 in /usr/local/lib/python3.8/dist-packages (from baal) (21.5.0)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.4.3 in /usr/local/lib/python3.8/dist-packages (from baal) (3.6.2)\n",
            "Requirement already satisfied: torchmetrics<0.10.0,>=0.9.3 in /usr/local/lib/python3.8/dist-packages (from baal) (0.9.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.2 in /usr/local/lib/python3.8/dist-packages (from baal) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from baal) (1.0.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from baal) (1.13.0+cu116)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from baal) (1.7.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.62.2 in /usr/local/lib/python3.8/dist-packages (from baal) (4.64.1)\n",
            "Requirement already satisfied: Pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from baal) (7.1.2)\n",
            "Requirement already satisfied: h5py<4.0.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from baal) (3.7.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.4.3->baal) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.4.3->baal) (1.0.6)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.4.3->baal) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.4.3->baal) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.4.3->baal) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.4.3->baal) (4.38.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.4.3->baal) (21.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.4.3->baal) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<2.0.0,>=1.0.0->baal) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<2.0.0,>=1.0.0->baal) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6.0->baal) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: segmentation-models-pytorch in /usr/local/lib/python3.8/dist-packages (0.3.1)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from segmentation-models-pytorch) (0.14.0+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from segmentation-models-pytorch) (4.64.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from segmentation-models-pytorch) (7.1.2)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.8/dist-packages (from segmentation-models-pytorch) (0.7.4)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.8/dist-packages (from segmentation-models-pytorch) (0.7.1)\n",
            "Requirement already satisfied: timm==0.4.12 in /usr/local/lib/python3.8/dist-packages (from segmentation-models-pytorch) (0.4.12)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.0+cu116)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.8/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install baal\n",
        "!pip install segmentation-models-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wEvOwdO3CQrM"
      },
      "outputs": [],
      "source": [
        "class SegmentationHead(nn.Sequential):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, activation=None, upsampling=1):\n",
        "        dropout = nn.Dropout2d(0.5)\n",
        "        conv2d = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size // 2\n",
        "        )\n",
        "        upsampling = (\n",
        "            nn.UpsamplingBilinear2d(scale_factor=upsampling) if upsampling > 1 else nn.Identity()\n",
        "        )\n",
        "        activation = Activation(activation)\n",
        "        super().__init__(dropout, conv2d, upsampling, activation)\n",
        "\n",
        "\n",
        "def add_dropout(\n",
        "    model: smp.Unet,\n",
        "    decoder_channels: List[int] = (256, 128, 64, 32, 16),\n",
        "    classes=1,\n",
        "    activation=None,\n",
        "):\n",
        "    seg_head = SegmentationHead(\n",
        "        in_channels=decoder_channels[-1],\n",
        "        out_channels=classes,\n",
        "        activation=activation,\n",
        "        kernel_size=3,\n",
        "    )\n",
        "    model.add_module(\"segmentation_head\", seg_head)\n",
        "    model.initialize()\n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    References:\n",
        "        Author: clcarwin\n",
        "        Site https://github.com/clcarwin/focal_loss_pytorch/blob/master/focalloss.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        if isinstance(alpha, (float, int)):\n",
        "            self.alpha = torch.Tensor([alpha, 1 - alpha])\n",
        "        if isinstance(alpha, list):\n",
        "            self.alpha = torch.Tensor(alpha)\n",
        "        self.size_average = size_average\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        if input.dim() > 2:\n",
        "            input = input.view(input.size(0), input.size(1), -1)  # N,C,H,W => N,C,H*W\n",
        "            input = input.transpose(1, 2)  # N,C,H*W => N,H*W,C\n",
        "            input = input.contiguous().view(-1, input.size(2))  # N,H*W,C => N*H*W,C\n",
        "        target = target.view(-1, 1)\n",
        "\n",
        "        logpt = F.log_softmax(input, dim=1)\n",
        "        logpt = logpt.gather(1, target)\n",
        "        logpt = logpt.view(-1)\n",
        "        pt = logpt.data.exp()\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            if self.alpha.type() != input.data.type():\n",
        "                self.alpha = self.alpha.type_as(input.data)\n",
        "            select = (target != 0).type(torch.LongTensor).to(self.alpha.device)\n",
        "            at = self.alpha.gather(0, select.data.view(-1))\n",
        "            logpt = logpt * at\n",
        "\n",
        "        loss = -1 * (1 - pt) ** self.gamma * logpt\n",
        "        if self.size_average:\n",
        "            return loss.mean()\n",
        "        else:\n",
        "            return loss.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XMuIz-pmFDU3"
      },
      "outputs": [],
      "source": [
        "def mean_regions(n, grid_size=16):\n",
        "    # Compute the mean uncertainty per regions.\n",
        "    # [batch_size, W, H]\n",
        "    n = torch.from_numpy(n[:, None, ...])\n",
        "    # [Batch_size, 1, grid, grid]\n",
        "    out = F.adaptive_avg_pool2d(n, grid_size)\n",
        "    return np.mean(out.view([-1, grid_size**2]).numpy(), -1)\n",
        "\n",
        "\n",
        "class ArrayDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, array, image_transforms=None, both_transforms=None):\n",
        "        self.array = array\n",
        "                \n",
        "        self.image_transforms = image_transforms\n",
        "        self.segment_transforms = transforms.Compose([\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.array)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        id, imagePath, segmentPath = self.array[index]\n",
        "        image = Image.open(imagePath).convert('RGB')\n",
        "        segment = Image.open(segmentPath).convert('L')\n",
        "        segment = self.segment_transforms(segment)        \n",
        "            \n",
        "        if self.image_transforms is not None:\n",
        "            image = self.image_transforms(image)\n",
        "        \n",
        "        # print(image.shape, segment.shape)\n",
        "\n",
        "        if image.shape != (3, 448, 448):\n",
        "            print(f\"Image shape is {image.shape}\")\n",
        "        if segment.shape != (1, 448, 448):\n",
        "            print(f\"Segment shape is {segment.shape}\")\n",
        "        \n",
        "        return image, segment\n",
        "    \n",
        "    def split(self, p=0.5):\n",
        "        count = len(self.array)\n",
        "        index = np.arange(count)\n",
        "        first = int(count * p)\n",
        "        return [\n",
        "            ArrayDataset(self.array[index[:first]], \n",
        "                    image_transforms=self.image_transforms), \n",
        "            ArrayDataset(self.array[index[first:]], \n",
        "                    image_transforms=self.image_transforms)\n",
        "        ]\n",
        "\n",
        "\n",
        "\n",
        "def get_datasets(initial_pool, path):\n",
        "    IM_SIZE = 224\n",
        "    \n",
        "    transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    X_dir = Path(path)/'train'/'images'\n",
        "    y_dir = Path(path)/'train'/'masks'\n",
        "\n",
        "    files = [y for y in X_dir.glob('*')] \n",
        "\n",
        "    for i in files:\n",
        "        assert((y_dir / i.name).exists())\n",
        "\n",
        "    data = np.array([(i, (y_dir / i.name)) for id, i in enumerate(files)])\n",
        "\n",
        "    dataset = ArrayDataset(data, image_transforms = transform)\n",
        "\n",
        "    active_set, test_set = dataset.split(0.8)\n",
        "    active_set = ActiveLearningDataset(active_set)\n",
        "    \n",
        "    active_set.label_randomly(initial_pool)\n",
        "    return active_set, test_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "0ONLRoriFEoG",
        "outputId": "9ad7f068-86c2-4fa6-a382-d22203afad06"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c994dd2b3b18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mactive_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_initial_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# We will use the FocalLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-4322127767f1>\u001b[0m in \u001b[0;36mget_datasets\u001b[0;34m(initial_pool, path)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mactive_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActiveLearningDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mactive_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_randomly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mactive_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/baal/active/dataset/base.py\u001b[0m in \u001b[0;36mlabel_randomly\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0msamples\u001b[0m \u001b[0mto\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_unlabelled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
          ]
        }
      ],
      "source": [
        "\n",
        "p_active_learning_steps = 200\n",
        "p_batch_size = 8\n",
        "p_initial_pool = 40\n",
        "p_query_size = 20\n",
        "p_lr = 0.001\n",
        "p_heuristic = \"random\"\n",
        "p_reduce=\"sum\"\n",
        "p_data_path = \"./data/roadsegm\"\n",
        "p_iterations=20\n",
        "p_leaning_epoch=30\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "active_set, test_set = get_datasets(p_initial_pool, p_data_path)\n",
        "\n",
        "# We will use the FocalLoss\n",
        "criterion = FocalLoss(gamma=2, alpha=0.25)\n",
        "\n",
        "# Our model is a simple Unet\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"resnext50_32x4d\",\n",
        "    encoder_depth=5,\n",
        "    encoder_weights=\"imagenet\",\n",
        "    decoder_use_batchnorm=False,\n",
        "    classes=1,\n",
        ")\n",
        "\n",
        "# Add a Dropout layerto use MC-Dropout\n",
        "add_dropout(model, classes=1, activation=None)\n",
        "\n",
        "# This will enable Dropout at test time.\n",
        "model = baal.bayesian.dropout.MCDropoutModule(model)\n",
        "\n",
        "# Put everything on GPU.\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "\n",
        "criterion = FocalLoss(gamma=2, alpha=0.25)\n",
        "# Make an optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=p_lr, momentum=0.9, weight_decay=5e-4)\n",
        "# Keep a copy of the original weights\n",
        "initial_weights = deepcopy(model.state_dict())\n",
        "\n",
        "# Add metrics\n",
        "model = baal.ModelWrapper(model, criterion)\n",
        "\n",
        "# Which heuristic you want to use?\n",
        "# We will use our custom reduction function.\n",
        "heuristic = baal.ModelWrapper.get_heuristic(p_heuristic, reduction=mean_regions)\n",
        "\n",
        "# The ALLoop is in charge of predicting the uncertainty and\n",
        "loop = baal.ActiveLearningLoop(\n",
        "    active_set,\n",
        "    model.predict_on_dataset_generator,\n",
        "    heuristic=heuristic,\n",
        "    query_size=p_query_size,\n",
        "    # Instead of predicting on the entire pool, only a subset is used\n",
        "    max_sample=1000,\n",
        "    batch_size=batch_size,\n",
        "    iterations=p_iterations,\n",
        "    use_cuda=use_cuda,\n",
        ")\n",
        "acc = []\n",
        "for epoch in tqdm(p_active_learning_steps):\n",
        "    # Following Gal et al. 2016, we reset the weights.\n",
        "    model.load_state_dict(initial_weights)\n",
        "    # Train 50 epochs before sampling.\n",
        "    model.train_on_dataset(\n",
        "        active_set, optimizer, batch_size, p_leaning_epoch, use_cuda\n",
        "    )\n",
        "\n",
        "    # Validation!\n",
        "    model.test_on_dataset(test_set, batch_size, use_cuda)\n",
        "    should_continue = loop.step()\n",
        "\n",
        "    logs = model.get_metrics()\n",
        "    pprint(logs)\n",
        "    acc.append(logs)\n",
        "    if not should_continue:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8tQfh8mh4Yv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
