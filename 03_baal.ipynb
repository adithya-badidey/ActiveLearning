{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KM6I2WSiBmMu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.13) or chardet (5.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.base.modules import Activation\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from baal import ActiveLearningDataset\n",
    "\n",
    "import argparse\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "\n",
    "import torch.backends\n",
    "from PIL import Image\n",
    "from torch import optim\n",
    "from torchvision.transforms import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import baal\n",
    "from baal.active import get_heuristic, ActiveLearningLoop\n",
    "from baal.bayesian.dropout import MCDropoutModule\n",
    "# from baal import ModelWrapper\n",
    "# from baal import ClassificationReport\n",
    "# from baal import PILToLongTensor\n",
    "\n",
    "try:\n",
    "    import segmentation_models_pytorch as smp\n",
    "except ImportError:\n",
    "    raise Exception(\"This example requires `smp`.\\n pip install segmentation_models_pytorch\")\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OMYkCTgRWBxe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Python Path\n",
      "Project Root Path: /home/default/workspace\n",
      "Project Source Root Path: /home/default/workspace/ActiveLearning\n",
      "Project Data Path: /home/default/workspace/ActiveLearning/data\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "# To be able to reference packages/modules in this repository, this\n",
    "# relative path must be added to the python path. Your notebook may be \n",
    "# in a different folder, so modify this variable to point to the src \n",
    "# folder.\n",
    "proj_notebooks_root = pathlib.Path().absolute()\n",
    "proj_root_path = proj_notebooks_root.parent\n",
    "data_path = proj_notebooks_root / \"data\"\n",
    "\n",
    "if proj_root_path not in sys.path:\n",
    "    sys.path.insert(0, proj_root_path.as_posix())\n",
    "    print(\"Updated Python Path\")\n",
    "\n",
    "print(f\"Project Root Path: {proj_root_path}\")\n",
    "print(f\"Project Source Root Path: {proj_notebooks_root}\")\n",
    "print(f\"Project Data Path: {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VpeLlZdACGwl",
    "outputId": "ef3a35dd-990b-40e2-de6c-f6ba9e22ae51",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install baal\n",
    "# !pip install segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dataset at  /home/default/workspace/ActiveLearning/data/ConglomerateConcreteCrackDataset\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_dir = data_path / 'ConglomerateConcreteCrackDataset'\n",
    "if not base_dir.exists():\n",
    "    dataset_url = 'https://data.lib.vt.edu/ndownloader/articles/16625056/versions/1'\n",
    "\n",
    "    ! wget {dataset_url} -P {data_path}\n",
    "    ! unzip -q {data_path / '1'} -d {data_path}\n",
    "    ! unzip -q {data_path / 'Conglomerate\\ Concrete\\ Crack\\ Detection.zip'} -d {data_path}\n",
    "    ! mv {data_path/'Conglomerate\\ Concrete\\ Crack\\ Detection'} {base_dir}\n",
    "    ! mv {data_path / 'README_congl_dataset.rtf'}  {data_path/'ConglomerateConcreteCrackDataset'}     \n",
    "    ! rm {data_path / 'Conglomerate\\ Concrete\\ Crack\\ Detection.zip'}\n",
    "    ! rm {data_path / '1'}\n",
    "else:\n",
    "    print(\"Found dataset at \", base_dir.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wEvOwdO3CQrM"
   },
   "outputs": [],
   "source": [
    "# class SegmentationHead(nn.Sequential):\n",
    "#     def __init__(self, in_channels, out_channels, kernel_size=3, activation=None, upsampling=1):\n",
    "#         dropout = nn.Dropout2d(0.5)\n",
    "#         conv2d = nn.Conv2d(\n",
    "#             in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size // 2\n",
    "#         )\n",
    "#         upsampling = (\n",
    "#             nn.UpsamplingBilinear2d(scale_factor=upsampling) if upsampling > 1 else nn.Identity()\n",
    "#         )\n",
    "#         activation = Activation(activation)\n",
    "#         super().__init__(dropout, conv2d, upsampling, activation)\n",
    "\n",
    "\n",
    "# def add_dropout(\n",
    "#     model: smp.Unet,\n",
    "#     decoder_channels: List[int] = (256, 128, 64, 32, 16),\n",
    "#     classes=1,\n",
    "#     activation=None,\n",
    "# ):\n",
    "#     seg_head = SegmentationHead(\n",
    "#         in_channels=decoder_channels[-1],\n",
    "#         out_channels=classes,\n",
    "#         activation=activation,\n",
    "#         kernel_size=3,\n",
    "#     )\n",
    "#     model.add_module(\"segmentation_head\", seg_head)\n",
    "#     model.initialize()\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    References:\n",
    "        Author: clcarwin\n",
    "        Site https://github.com/clcarwin/focal_loss_pytorch/blob/master/focalloss.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha, (float, int)):\n",
    "            self.alpha = torch.Tensor([alpha, 1 - alpha])\n",
    "        if isinstance(alpha, list):\n",
    "            self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim() > 2:\n",
    "            input = input.view(input.size(0), input.size(1), -1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1, 2)  # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1, input.size(2))  # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1, 1)\n",
    "\n",
    "        logpt = F.log_softmax(input, dim=1)\n",
    "        logpt = logpt.gather(1, target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = logpt.data.exp()\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type() != input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            select = (target != 0).type(torch.LongTensor).to(self.alpha.device)\n",
    "            at = self.alpha.gather(0, select.data.view(-1))\n",
    "            logpt = logpt * at\n",
    "\n",
    "        loss = -1 * (1 - pt) ** self.gamma * logpt\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XMuIz-pmFDU3"
   },
   "outputs": [],
   "source": [
    "def mean_regions(n, grid_size=16):\n",
    "    # Compute the mean uncertainty per regions.\n",
    "    # [batch_size, W, H]\n",
    "    n = torch.from_numpy(n[:, None, ...])\n",
    "    # [Batch_size, 1, grid, grid]\n",
    "    out = F.adaptive_avg_pool2d(n, grid_size)\n",
    "    return np.mean(out.view([-1, grid_size**2]).numpy(), -1)\n",
    "\n",
    "\n",
    "class ArrayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, array, image_transforms=None, both_transforms=None):\n",
    "        self.array = array\n",
    "                \n",
    "        self.image_transforms = image_transforms\n",
    "        self.segment_transforms = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.array)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        imagePath, segmentPath = self.array[index]\n",
    "        image = Image.open(imagePath).convert('RGB')\n",
    "        segment = Image.open(segmentPath).convert('L')\n",
    "        segment = self.segment_transforms(segment)        \n",
    "            \n",
    "        if self.image_transforms is not None:\n",
    "            image = self.image_transforms(image)\n",
    "        \n",
    "        # print(image.shape, segment.shape)\n",
    "\n",
    "        if image.shape != (3, 448, 448):\n",
    "            print(f\"Image shape is {image.shape}\")\n",
    "        if segment.shape != (1, 448, 448):\n",
    "            print(f\"Segment shape is {segment.shape}\")\n",
    "        \n",
    "        return image, segment.type(torch.int64) \n",
    "    \n",
    "    def split(self, p=0.5):\n",
    "        count = len(self.array)\n",
    "        index = np.arange(count)\n",
    "        first = int(count * p)\n",
    "        return [\n",
    "            ArrayDataset(self.array[index[:first]], \n",
    "                    image_transforms=self.image_transforms), \n",
    "            ArrayDataset(self.array[index[first:]], \n",
    "                    image_transforms=self.image_transforms)\n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "def get_datasets(initial_pool, path):\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    X_dir = path/'Train'/'images'\n",
    "    y_dir = path/'Train'/'masks'\n",
    "\n",
    "    files = [y for y in X_dir.glob('*')]\n",
    "\n",
    "    for i in files:\n",
    "        assert((y_dir / i.name).exists())\n",
    "\n",
    "    data = np.array([(i, (y_dir / i.name)) for id, i in enumerate(files)])\n",
    "\n",
    "    dataset = ArrayDataset(data, image_transforms = transform)\n",
    "\n",
    "\n",
    "    active_set, test_set = dataset.split(0.8)\n",
    "    print(\"Active Set: \", len(active_set))\n",
    "    print(\"Test Set: \", len(test_set))\n",
    "    \n",
    "    active_set = ActiveLearningDataset(active_set)\n",
    "    \n",
    "    active_set.label_randomly(initial_pool)\n",
    "    return active_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = smp.Unet('resnet34', \n",
    "#                  classes=1, \n",
    "#                  decoder_use_batchnorm=False)\n",
    "\n",
    "# # Add a Dropout layerto use MC-Dropout\n",
    "# # add_dropout(model, classes=1, activation=None)\n",
    "\n",
    "# # This will enable Dropout at test time.\n",
    "# # model = MCDropoutModule(model)\n",
    "\n",
    "# # Put everything on GPU.\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchinfo import summary\n",
    "# summary(model, input_size=[16, 3, 224, 224], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.segmentation_head[1] = nn.Dropout2d(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.segmentation_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Cuda: True\n",
      "Active Set:  7919\n",
      "Test Set:  1980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 448, 448]), torch.Size([1, 448, 448]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "p_active_learning_steps = 3\n",
    "\n",
    "p_initial_pool = 60\n",
    "p_query_size = 60\n",
    "p_query_interations = 20\n",
    "\n",
    "p_heuristic = \"random\"\n",
    "p_reduce=\"sum\"\n",
    "\n",
    "p_leaning_epochs=30\n",
    "p_lr = 0.001\n",
    "p_batch_size = 16\n",
    "\n",
    "p_classes = 2\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "print(\"Use Cuda:\", use_cuda)\n",
    "\n",
    "active_set, test_set = get_datasets(p_initial_pool, base_dir)\n",
    "\n",
    "image, segment = active_set[0]\n",
    "image.shape, segment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We will use the FocalLoss\n",
    "if p_classes > 1:\n",
    "    criterion = FocalLoss(gamma=2, alpha=0.25)\n",
    "else:\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# # Our model is a simple Unet\n",
    "# model = smp.Unet(\n",
    "#     encoder_name=\"resnext50_32x4d\",\n",
    "#     encoder_depth=5,\n",
    "#     encoder_weights=\"imagenet\",\n",
    "#     decoder_use_batchnorm=False,\n",
    "#     classes=1,\n",
    "# )\n",
    "# add_dropout(model, classes=1, activation=None)\n",
    "\n",
    "model = smp.Unet('resnet34', \n",
    "                 classes=p_classes, \n",
    "                 decoder_use_batchnorm=False)\n",
    "model.segmentation_head[1] = nn.Dropout2d(0.5)\n",
    "\n",
    "# Add a Dropout layerto use MC-Dropout\n",
    "# add_dropout(model, classes=1, activation=None)\n",
    "\n",
    "# This will enable Dropout at test time.\n",
    "model = MCDropoutModule(model)\n",
    "\n",
    "# Put everything on GPU.\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "# Make an optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=p_lr, momentum=0.9, weight_decay=5e-4)\n",
    "# Keep a copy of the original weights\n",
    "initial_weights = deepcopy(model.state_dict())\n",
    "\n",
    "# Add metrics\n",
    "model = baal.ModelWrapper(model, criterion)\n",
    "\n",
    "# Which heuristic you want to use?\n",
    "# We will use our custom reduction function.\n",
    "heuristic = get_heuristic(p_heuristic, reduction=mean_regions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[769814-MainThread] [baal.modelwrapper:train_on_dataset:83] \u001b[2m2022-12-16T01:13:53.060254Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStarting training             \u001b[0m \u001b[36mdataset\u001b[0m=\u001b[35m60\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m30\u001b[0m\n",
      "[769814-MainThread] [baal.modelwrapper:train_on_dataset:94] \u001b[2m2022-12-16T01:16:19.370796Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTraining complete             \u001b[0m \u001b[36mtrain_loss\u001b[0m=\u001b[35m0.02492203563451767\u001b[0m\n",
      "[769814-MainThread] [baal.modelwrapper:test_on_dataset:123] \u001b[2m2022-12-16T01:16:19.399324Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStarting evaluating           \u001b[0m \u001b[36mdataset\u001b[0m=\u001b[35m1980\u001b[0m\n",
      "[769814-MainThread] [baal.modelwrapper:test_on_dataset:133] \u001b[2m2022-12-16T01:17:11.592061Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mEvaluation complete           \u001b[0m \u001b[36mtest_loss\u001b[0m=\u001b[35m0.02781635895371437\u001b[0m\n",
      "[769814-MainThread] [baal.modelwrapper:predict_on_dataset_generator:232] \u001b[2m2022-12-16T01:17:11.945785Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStart Predict                 \u001b[0m \u001b[36mdataset\u001b[0m=\u001b[35m1000\u001b[0m\n",
      "\n",
      "  0%|          | 0/32 [00:01<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [03:20<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA ran out of memory while BaaL tried to replicate data. See the exception above.\n                    Use `replicate_in_memory=False` in order to reduce the memory requirements.\n                    Note that there will be some speed trade-offs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/baal/modelwrapper.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, data, iterations, cuda)\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/baal/bayesian/common.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/segmentation_models_pytorch/base/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/segmentation_models_pytorch/encoders/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 7.66 GiB (GPU 0; 19.50 GiB total capacity; 9.45 GiB already allocated; 7.18 GiB free; 10.81 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-873d98e70aee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Validation!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mshould_continue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#     logs = model.get_metrics()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/baal/active/active_loop.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, pool)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mto_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muncertainty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheuristic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ranks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0mto_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/baal/active/heuristics/heuristics.py\u001b[0m in \u001b[0;36mget_ranks\u001b[0;34m(self, predictions)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_uncertainties_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_uncertainties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/baal/active/heuristics/heuristics.py\u001b[0m in \u001b[0;36mget_uncertainties_generator\u001b[0;34m(self, predictions)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \"\"\"\n\u001b[1;32m    174\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_uncertainties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/baal/modelwrapper.py\u001b[0m in \u001b[0;36mpredict_on_dataset_generator\u001b[0;34m(self, dataset, batch_size, iterations, use_cuda, workers, collate_fn, half, verbose)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_on_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/baal/modelwrapper.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, data, iterations, cuda)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                     raise RuntimeError(\n\u001b[0m\u001b[1;32m    384\u001b[0m                         \"\"\"CUDA ran out of memory while BaaL tried to replicate data. See the exception above.\n\u001b[1;32m    385\u001b[0m                     \u001b[0mUse\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mreplicate_in_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morder\u001b[0m \u001b[0mto\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmemory\u001b[0m \u001b[0mrequirements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA ran out of memory while BaaL tried to replicate data. See the exception above.\n                    Use `replicate_in_memory=False` in order to reduce the memory requirements.\n                    Note that there will be some speed trade-offs"
     ]
    }
   ],
   "source": [
    "\n",
    "# The ALLoop is in charge of predicting the uncertainty and\n",
    "loop = ActiveLearningLoop(\n",
    "    active_set,\n",
    "    model.predict_on_dataset_generator,\n",
    "    heuristic=heuristic,\n",
    "    query_size=p_query_size,\n",
    "    # Instead of predicting on the entire pool, only a subset is used\n",
    "    max_sample=1000,\n",
    "    batch_size=p_batch_size,\n",
    "    iterations=p_query_interations,\n",
    "    use_cuda=use_cuda,\n",
    ")\n",
    "acc = []\n",
    "for epoch in tqdm(range(p_active_learning_steps)):\n",
    "    # Following Gal et al. 2016, we reset the weights.\n",
    "    model.load_state_dict(initial_weights)\n",
    "    # Train 50 epochs before sampling.\n",
    "    \n",
    "    model.train_on_dataset(\n",
    "        active_set, \n",
    "        optimizer, \n",
    "        p_batch_size,\n",
    "        p_leaning_epochs,\n",
    "        use_cuda,\n",
    "        workers=12\n",
    "    )\n",
    "\n",
    "    # Validation!\n",
    "    model.test_on_dataset(test_set, p_batch_size, use_cuda)\n",
    "    should_continue = loop.step()\n",
    "\n",
    "#     logs = model.get_metrics()\n",
    "    pprint(logs)\n",
    "    acc.append(logs)\n",
    "    if not should_continue:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
